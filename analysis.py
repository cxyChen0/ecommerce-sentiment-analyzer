import os
from dotenv import load_dotenv

load_dotenv()

# å°è¯•å¯¼å…¥OpenAIï¼Œå¦‚å¤±è´¥åˆ™è®¾ç½®ä¸ºNone
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OpenAI = None
    OPENAI_AVAILABLE = False


def get_client(api_key):
    """è·å–OpenAIå…¼å®¹å®¢æˆ·ç«¯"""
    if not OPENAI_AVAILABLE:
        return None
    key = api_key if api_key else os.getenv("ALIYUN_API_KEY")
    if not key:
        return None
    return OpenAI(api_key=key, base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")


# === é€šç”¨æµå¼åŒ…è£…å™¨ ===
# === é€šç”¨æµå¼åŒ…è£…å™¨ (æ”¯æŒæ·±åº¦æ€è€ƒæ¨¡å¼) ===
def stream_wrapper(client, model, messages):
    # ç¬¬ä¸€è¡Œè¾“å‡ºæ¨¡å‹èº«ä»½
    yield f"> ğŸ¤– **å½“å‰æ™ºå›Šå›¢**ï¼š`{model}` \n\n"

    # å¦‚æœæ˜¯æ”¯æŒæ€è€ƒçš„æ¨¡å‹ï¼Œå¯ä»¥åœ¨ extra_body ä¸­å¼€å¯ï¼ˆè§†å…·ä½“ API æ¸ é“è€Œå®šï¼Œé˜¿é‡Œäº‘ç™¾ç‚¼é€šå¸¸è‡ªåŠ¨æ”¯æŒï¼‰
    extra_params = {}
    if "r1" in model.lower() or "deepseek" in model.lower():
        extra_params = {"enable_thinking": True}

    try:
        stream = client.chat.completions.create(
            model=model,
            messages=messages,
            stream=True,
            extra_body=extra_params
        )

        is_thinking = False  # æ ‡è®°æ˜¯å¦æ­£åœ¨è¾“å‡ºæ€è€ƒå†…å®¹
        has_answered = False  # æ ‡è®°æ˜¯å¦å¼€å§‹å›ç­”æ­£æ–‡

        for chunk in stream:
            if chunk.choices:
                delta = chunk.choices[0].delta

                # --- å¤„ç†æ€è€ƒè¿‡ç¨‹ (Reasoning Content) ---
                if hasattr(delta, "reasoning_content") and delta.reasoning_content:
                    # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ£€æµ‹åˆ°æ€è€ƒå†…å®¹ï¼Œè¾“å‡ºä¸€ä¸ªæ¼‚äº®çš„å¼•ç”¨å¤´
                    if not is_thinking:
                        yield "> ğŸ§  **æ·±åº¦æ€è€ƒè¿‡ç¨‹**ï¼š\n> "
                        is_thinking = True

                    # ç¡®ä¿æ¢è¡Œç¬¦ä¹Ÿèƒ½ä¿æŒåœ¨å¼•ç”¨å—(>)å†…
                    content = delta.reasoning_content.replace("\n", "\n> ")
                    yield content

                # --- å¤„ç†æ­£æ–‡å›å¤ (Content) ---
                if hasattr(delta, "content") and delta.content:
                    # å¦‚æœä¹‹å‰åœ¨æ€è€ƒï¼Œç°åœ¨å¼€å§‹å›ç­”äº†ï¼ŒåŠ ä¸€ä¸ªåˆ†å‰²çº¿
                    if is_thinking and not has_answered:
                        yield "\n\n---\n\n### ğŸ“ æ·±åº¦åˆ†æç»“è®º\n\n"
                        is_thinking = False  # æ€è€ƒç»“æŸ
                        has_answered = True

                    yield delta.content

    except Exception as e:
        yield f"âŒ AI æ€è€ƒä¸­æ–­: {str(e)}"


# ==========================================
# 1. å•å“æ·±åº¦åˆ†æ (Prompt å‡çº§ç‰ˆ)
# ==========================================
def analyze_single_product_stream(comments_list, api_key=None, model="deepseek-v3.2-exp"):
    client = get_client(api_key)
    if not client:
        yield "âŒ æœªé…ç½® API Key"
        return

    # æ•°æ®é¢„å¤„ç†
    valid_comments = [str(c) for c in comments_list if len(str(c)) > 4]
    # ç¨å¾®å¢åŠ è¾“å…¥é‡ï¼Œè®©åˆ†ææ›´å‡†ç¡®ï¼ˆå‰ææ˜¯æ¨¡å‹æ”¯æŒé•¿ä¸Šä¸‹æ–‡ï¼Œç°åœ¨çš„ä¸»æµæ¨¡å‹éƒ½æ”¯æŒï¼‰
    text_input = "\n".join(valid_comments[:60])

    system_prompt = """
    ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´ç»éªŒçš„**ç”µå•†æ¶ˆè´¹è€…è¡Œä¸ºåˆ†æä¸“å®¶**ã€‚è¯·åŸºäºæä¾›çš„ç”¨æˆ·è¯„è®ºæ•°æ®ï¼ŒæŒ–æ˜æ•°æ®èƒŒåçš„æ·±å±‚é€»è¾‘ï¼Œå¹¶è¾“å‡ºä¸€ä»½**é«˜é¢œå€¼ã€ç»“æ„æ¸…æ™°ã€æ´å¯Ÿæ·±åˆ»**çš„MarkdownæŠ¥å‘Šã€‚

    ### ğŸ¨ è¾“å‡ºé£æ ¼è¦æ±‚ï¼š
    1. **æ’ç‰ˆç¾è§‚**ï¼šå¤§é‡ä½¿ç”¨Emojiå›¾æ ‡ï¼ˆå¦‚ ğŸ“Š, ğŸ˜¡, ğŸ’¡ï¼‰æ¥å¢å¼ºå¯è¯»æ€§ã€‚
    2. **ç»“æ„æ¸…æ™°**ï¼šä½¿ç”¨ H3 (###) æ ‡é¢˜åˆ†å±‚ã€‚
    3. **é‡ç‚¹çªå‡º**ï¼šå…³é”®æ•°æ®æˆ–ç»“è®ºè¯·ä½¿ç”¨ **åŠ ç²—** æˆ– `é«˜äº®`ã€‚
    4. **å¼•ç”¨åŸæ–‡**ï¼šåœ¨åˆ†æç—›ç‚¹æ—¶ï¼Œå¿…é¡»æ‘˜å½•1-2å¥å…¸å‹çš„ç”¨æˆ·åŸè¯ä½œä¸ºä½è¯ï¼ˆä½¿ç”¨ > å¼•ç”¨å—ï¼‰ã€‚

    ### ğŸ“ æŠ¥å‘Šç»“æ„æ¨¡æ¿ï¼š
    # ğŸ›ï¸ [å•†å“åç§°] æ·±åº¦ä½“éªŒåˆ†ææŠ¥å‘Š

    ### 1. ğŸ“Š æƒ…æ„Ÿæ°”è±¡å°
    - **æ•´ä½“è¯„åˆ†é¢„ä¼°**ï¼š(ä¾‹å¦‚ï¼šâ­â­â­â­ 4.2/5.0)
    - **å¥½è¯„/å·®è¯„æ¯”**ï¼š(ä¼°ç®—ç™¾åˆ†æ¯”)
    - **ç”¨æˆ·æƒ…ç»ªå…³é”®è¯**ï¼š(åˆ—å‡º5ä¸ªæœ€é«˜é¢‘çš„å½¢å®¹è¯ï¼Œå¦‚ï¼š`æƒŠå–œ`ã€`å¤±æœ›`...)

    ### 2. ğŸ˜¡ æ ¸å¿ƒç—›ç‚¹æ·±æŒ– (Top 3)
    *æŒ–æ˜ç”¨æˆ·å·®è¯„èƒŒåçš„çœŸå®éœ€æ±‚ï¼Œä¸ä»…ä»…æ˜¯ç½—åˆ—é—®é¢˜ï¼Œè¦åˆ†æâ€œä¸ºä»€ä¹ˆâ€ã€‚*
    - **ç—›ç‚¹ä¸€**ï¼š[ç®€çŸ­æ ‡é¢˜]
      - ğŸ” *ç°è±¡æè¿°*ï¼š...
      - ğŸ’¬ *ç”¨æˆ·åŸå£°*ï¼š> "..."
      - ğŸ”¥ *ä¸¥é‡ç¨‹åº¦*ï¼š(é«˜/ä¸­/ä½)
    (ä¾æ¬¡ç±»æ¨...)

    ### 3. ğŸ‘¤ è°åœ¨ä¹°å•ï¼Ÿ(ç”¨æˆ·ç”»åƒ)
    - **å…¸å‹äººç¾¤**ï¼š(ä¾‹å¦‚ï¼šè¿½æ±‚æ€§ä»·æ¯”çš„å­¦ç”Ÿå…šã€æ³¨é‡å“è´¨çš„å®å¦ˆ...)
    - **æ ¸å¿ƒä½¿ç”¨åœºæ™¯**ï¼š(ä¾‹å¦‚ï¼šå®¿èˆè¿½å‰§ã€åŠå…¬å®¤åˆä¼‘...)

    ### 4. ğŸ’¡ é¦–å¸­è¿è¥å®˜å»ºè®®
    - **äº§å“è¿­ä»£**ï¼š(é’ˆå¯¹ç—›ç‚¹çš„å…·ä½“æ”¹è¿›æ–¹æ¡ˆ)
    - **è¥é”€è¯æœ¯**ï¼š(é’ˆå¯¹å¥½è¯„ç‚¹çš„æ”¾å¤§ç­–ç•¥)
    """

    messages = [
        {'role': 'system', 'content': system_prompt},
        {'role': 'user', 'content': f"ã€ç”¨æˆ·è¯„è®ºæ•°æ®ã€‘ï¼š\n{text_input}"}
    ]

    yield from stream_wrapper(client, model, messages)


# ==========================================
# 2. å¸‚åœºçˆ†æ¬¾åˆ†æ (Prompt å‡çº§ç‰ˆ)
# ==========================================
def analyze_market_trends_stream(comments_list, api_key=None, model="qwen-plus"):
    client = get_client(api_key)
    if not client:
        yield "âŒ æœªé…ç½® API Key"
        return

    text_input = "\n".join(comments_list[:100])

    system_prompt = """
    ä½ æ˜¯ä¸€ä½**ç”µå•†å¸‚åœºè¶‹åŠ¿æˆ˜ç•¥é¡¾é—®**ã€‚åŸºäºè¿™æ‰¹çƒ­é”€å•†å“çš„è¯„è®ºï¼Œè¯·æ´å¯Ÿè¯¥å“ç±»çš„**çˆ†æ¬¾åŸºå› **å’Œ**å¸‚åœºæœºä¼š**ã€‚

    ### ğŸ¨ è¾“å‡ºè¦æ±‚ï¼š
    - è¯­è¨€çŠ€åˆ©ã€ä¸“ä¸šï¼Œæ‹’ç»ä¸‡é‡‘æ²¹å¼çš„åºŸè¯ã€‚
    - ä½¿ç”¨ Markdown è¡¨æ ¼è¿›è¡Œå½’çº³ã€‚

    ### ğŸ“ æŠ¥å‘Šç»“æ„ï¼š
    # ğŸ”¥ è¡Œä¸šçˆ†æ¬¾åŸºå› è§£ç æŠ¥å‘Š

    ### 1. ğŸ† ç”¨æˆ·ä¹°å•çš„ç†ç”± (The "Why")
    *ç”¨æˆ·é€‰æ‹©ä¸‹å•çš„å†³å®šæ€§å› ç´ æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆæŒ‰æƒé‡æ’åºï¼‰*
    - ğŸ¥‡ **ç¬¬ä¸€è¦ç´ **ï¼š...
    - ğŸ¥ˆ **ç¬¬äºŒè¦ç´ **ï¼š...
    - ğŸ¥‰ **ç¬¬ä¸‰è¦ç´ **ï¼š...

    ### 2. ğŸ’– ç”¨æˆ·é«˜é¢‘çˆ½ç‚¹ (Magic Moments)
    *ç”¨æˆ·åœ¨ä»€ä¹ˆç¬é—´è§‰å¾—"ä¹°å€¼äº†"ï¼Ÿ*
    (è¯·åˆ—ä¸¾å…·ä½“åœºæ™¯)

    ### 3. ğŸ“‰ è“æµ·æœºä¼šç‚¹ (æœªè¢«æ»¡è¶³çš„éœ€æ±‚)
    *å³ä¾¿åœ¨çˆ†æ¬¾ä¸­ï¼Œç”¨æˆ·ä¾ç„¶åœ¨æŠ±æ€¨ä»€ä¹ˆï¼Ÿè¿™é‡Œå¾€å¾€è—ç€ä¸‹ä¸€ä¸ªæœºä¼šã€‚*
    - ğŸŒŠ **æœºä¼šç‚¹ 1**ï¼š...
    - ğŸŒŠ **æœºä¼šç‚¹ 2**ï¼š...

    ### 4. ğŸš€ çˆ†æ¬¾æ–‡æ¡ˆçµæ„Ÿ
    *åŸºäºç”¨æˆ·å–œæ¬¢çš„ç‚¹ï¼Œç”Ÿæˆ3æ¡å¸ç›çš„çŸ­è§†é¢‘/è¯¦æƒ…é¡µæ–‡æ¡ˆæ ‡é¢˜ã€‚*
    1. ...
    2. ...
    3. ...
    """

    messages = [{'role': 'system', 'content': system_prompt}, {'role': 'user', 'content': text_input}]
    yield from stream_wrapper(client, model, messages)


# ==========================================
# 3. ç«å“æ¯”å¯¹ (Prompt å‡çº§ç‰ˆ)
# ==========================================
def analyze_competitor_comparison_stream(my_product_name, my_comments, competitor_comments, api_key=None,
                                         model="qwen-max"):
    client = get_client(api_key)
    if not client:
        yield "âŒ æœªé…ç½® API Key"
        return

    my_text = "\n".join([str(c) for c in my_comments[:40]])
    comp_text = "\n".join([str(c) for c in competitor_comments[:60]])

    system_prompt = f"""
    ä½ æ˜¯ä¸€ä½**ç”µå•†ç«äº‰æƒ…æŠ¥åˆ†æå¸ˆ**ã€‚æˆ‘ä»¬æ­£åœ¨è¿›è¡Œä¸€åœºæ®‹é…·çš„å¸‚åœºå¯¹å†³ã€‚
    **æœ¬å“**ï¼š{my_product_name}
    **ç«å“**ï¼šå¸‚åœºä¸Šçš„å¤´éƒ¨çƒ­é”€ç«å“

    è¯·è¾“å‡ºä¸€ä»½**æˆ˜æ–—æª„æ–‡**çº§åˆ«çš„å¯¹æ¯”åˆ†ææŠ¥å‘Šï¼Œé‡ç‚¹åœ¨äº**æ‰¾å·®è·ã€æ‰¾ä¼˜åŠ¿**ã€‚

    ### ğŸ“ æŠ¥å‘Šç»“æ„ï¼š
    # âš”ï¸ å·…å³°å¯¹å†³ï¼šæœ¬å“ vs ç«å“

    ### 1. ğŸ“Š æ ¸å¿ƒç»´åº¦æ¨ªå‘æµ‹è¯„ (è¡¨æ ¼å¯¹æ¯”)
    | ç»´åº¦ | ğŸŸ¢ æœ¬å“è¡¨ç° | ğŸ”´ ç«å“è¡¨ç° | èƒœå‡ºæ–¹ |
    | :--- | :--- | :--- | :--- |
    | **ä»·æ ¼/æ€§ä»·æ¯”** | ... | ... | ... |
    | **äº§å“è´¨é‡/åšå·¥** | ... | ... | ... |
    | **åŠŸèƒ½ä½“éªŒ** | ... | ... | ... |
    | **æœåŠ¡/ç‰©æµ** | ... | ... | ... |

    ### 2. ğŸ›¡ï¸ æˆ‘ä»¬çš„æŠ¤åŸæ²³ (æ ¸å¿ƒä¼˜åŠ¿)
    *æˆ‘ä»¬å“ªé‡Œæ¯”ç«å“å¼ºï¼Ÿè¿™æ˜¯æˆ‘ä»¬å¿…é¡»æ­»å®ˆçš„é˜µåœ°ã€‚*

    ### 3. âš ï¸ æˆ‘ä»¬çš„é˜¿å–€ç‰æ–¯ä¹‹è¸µ (è‡´å‘½å¼±ç‚¹)
    *ç«å“å“ªé‡Œæ¯”æˆ‘ä»¬å¼ºï¼Ÿè¿™æ˜¯å¿…é¡»ç«‹åˆ»è¡¥é½çš„çŸ­æ¿ã€‚*
    *(è¯·ç›´è¨€ä¸è®³ï¼Œä¸è¦å®¢æ°”)*

    ### 4. ğŸš€ åå‡»æˆ˜æœ¯æ¿ (Action Plan)
    *ä¸ºäº†æ‰“èµ¢è¿™åœºä»—ï¼Œæ¥ä¸‹æ¥ä¸¤å‘¨æˆ‘ä»¬å¿…é¡»åšçš„ä¸‰ä»¶äº‹ï¼š*
    1. ...
    2. ...
    3. ...
    """

    user_prompt = f"ã€æœ¬å“ç”¨æˆ·åé¦ˆã€‘\n{my_text}\n\nã€ç«å“ç”¨æˆ·åé¦ˆã€‘\n{comp_text}"
    messages = [{'role': 'system', 'content': system_prompt}, {'role': 'user', 'content': user_prompt}]

    yield from stream_wrapper(client, model, messages)