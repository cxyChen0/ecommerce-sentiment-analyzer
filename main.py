import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime, timedelta
import random
import time
from openai import OpenAI

# === å¯¼å…¥åˆšæ‰å†™çš„çˆ¬è™«è„šæœ¬ ===
# æ³¨æ„ï¼šreal_crawler.py å¿…é¡»å’Œ main.py åœ¨åŒä¸€ä¸ªæ–‡ä»¶å¤¹å†…
try:
    from real_crawler import ECommerceCrawler

    HAS_CRAWLER = True
except ImportError:
    HAS_CRAWLER = False

# ==========================================
# 1. åŸºç¡€é…ç½®
# ==========================================

st.set_page_config(page_title="ç”µå•†å®¢æˆ·ä½“éªŒåˆ†æç³»ç»Ÿ", page_icon="ğŸ›ï¸", layout="wide")

import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# AI é…ç½®
USE_MOCK_AI = True
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "")
BASE_URL = "https://api.deepseek.com"


def analyze_sentiment_with_ai(text):
    """
    è°ƒç”¨AIè¿›è¡Œæƒ…æ„Ÿåˆ†æ (DeepSeek)
    """
    if USE_MOCK_AI:
        # æ¼”ç¤ºæ¨¡å¼ï¼šæ ¹æ®å…³é”®è¯ç®€å•åˆ¤æ–­
        time.sleep(0.1)
        keywords = ["å·®", "æ…¢", "å", "å‘çƒ­", "ç ´æŸ", "ä¸è¡Œ", "å¡é¡¿"]
        if any(k in text for k in keywords):
            return "è´Ÿé¢", round(random.uniform(0.8, 0.99), 2)
        elif len(text) > 15:
            return "æ­£é¢", round(random.uniform(0.8, 0.99), 2)
        else:
            return "ä¸­æ€§", round(random.uniform(0.5, 0.7), 2)

    try:
        # çœŸå®è°ƒç”¨ DeepSeek API
        client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=BASE_URL)
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "åˆ¤æ–­æƒ…æ„Ÿå€¾å‘ï¼Œè¿”å›ï¼šæ­£é¢ã€è´Ÿé¢ã€æˆ–ä¸­æ€§ã€‚"},
                {"role": "user", "content": text},
            ]
        )
        return response.choices[0].message.content.strip(), 0.95
    except:
        return "ä¸­æ€§", 0.0


# ==========================================
# 2. æ ¸å¿ƒé€»è¾‘ï¼šè¿æ¥å‰åç«¯
# ==========================================

def get_real_data(url):
    """
    è¿æ¥ real_crawler.py è·å–çœŸå®æ•°æ®ï¼Œå¹¶è¡¥å……AIåˆ†æç»“æœ
    """
    status_text = st.empty()
    progress_bar = st.progress(0)

    status_text.text("æ­£åœ¨å¯åŠ¨çˆ¬è™«å¼•æ“...")

    # 1. è°ƒç”¨åç«¯çˆ¬è™«
    crawler = ECommerceCrawler()
    # æ³¨æ„ï¼šå¦‚æœ crawler.run è¿”å› None (æ¯”å¦‚è¢«åçˆ¬æ‹¦æˆª)ï¼Œæˆ‘ä»¬éœ€è¦å¤„ç†
    df_raw = crawler.run(url)
    progress_bar.progress(50)

    if df_raw is None or df_raw.empty:
        status_text.error("æŠ“å–å¤±è´¥ï¼å¯èƒ½åŸå› ï¼š1.Cookieè¿‡æœŸ 2.åçˆ¬æ‹¦æˆª 3.ç½‘ç»œè¶…æ—¶ã€‚å·²è‡ªåŠ¨åˆ‡æ¢å›æ¼”ç¤ºæ•°æ®ã€‚")
        time.sleep(2)
        return fetch_mock_data(url)  # å¤±è´¥æ—¶å›é€€åˆ°æ¨¡æ‹Ÿæ•°æ®

    status_text.text(f"æˆåŠŸæŠ“å– {len(df_raw)} æ¡è¯„è®ºï¼Œæ­£åœ¨è¿›è¡Œ AI æƒ…æ„Ÿåˆ†æ...")

    # 2. å¯¹æŠ“å–åˆ°çš„æ¯ä¸€æ¡è¯„è®ºè¿›è¡Œ AI åˆ†æ
    analyzed_data = []
    total = len(df_raw)
    for index, row in df_raw.iterrows():
        sentiment, conf = analyze_sentiment_with_ai(row['content'])
        analyzed_data.append({
            "content": row['content'],
            "date": row['date'],
            "sentiment": sentiment,
            "confidence": conf
        })
        # æ›´æ–°è¿›åº¦æ¡
        current_progress = 50 + int((index / total) * 50)
        progress_bar.progress(min(current_progress, 100))

    df_comments = pd.DataFrame(analyzed_data)

    # 3. è¡¥å……é”€é‡æ•°æ®
    # (æ³¨ï¼šå•æ¬¡çˆ¬å–å¾ˆéš¾è·å¾—å†å²é”€é‡æ›²çº¿ï¼Œè¿™é‡Œé€šå¸¸éœ€è¦ç”¨æ¨¡æ‹Ÿæ•°æ®æ¥å¡«è¡¥å›¾è¡¨)
    df_sales = generate_mock_sales_data()

    status_text.success("åˆ†æå®Œæˆï¼")
    time.sleep(1)
    status_text.empty()
    progress_bar.empty()

    return df_sales, df_comments


def fetch_mock_data(url):
    """
    (åŸæœ‰çš„) æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå‡½æ•°ï¼Œç”¨äºæ¼”ç¤ºæˆ–çˆ¬è™«å¤±è´¥æ—¶çš„å…œåº•
    """
    # ... ä¿ç•™åŸæœ‰çš„æ¨¡æ‹Ÿé€»è¾‘ä»¥ä¾¿æ¼”ç¤º ...
    # ç®€å†™ç‰ˆï¼š
    df_sales = generate_mock_sales_data()

    comments_pool = [
        ("ç‰©æµè¶…çº§å¿«ï¼Œç¬¬äºŒå¤©å°±åˆ°äº†ï¼", "æ­£é¢"),
        ("è´¨é‡ä¸€èˆ¬èˆ¬ï¼Œå¯¹å¾—èµ·è¿™ä¸ªä»·æ ¼å§ã€‚", "ä¸­æ€§"),
        ("å®¢æœæ€åº¦å¤ªå·®äº†ï¼ŒåŠå¤©ä¸å›æ¶ˆæ¯ã€‚", "è´Ÿé¢"),
        ("éå¸¸æ»¡æ„çš„ä¸€æ¬¡è´­ç‰©ï¼Œä¸‹æ¬¡è¿˜æ¥ã€‚", "æ­£é¢"),
        ("ç”µæ± ä¸å¤ªè€ç”¨ï¼Œå‘çƒ­ä¸¥é‡ã€‚", "è´Ÿé¢")
    ]
    fetched_comments = []
    for _ in range(20):
        text, _ = random.choice(comments_pool)
        sent, conf = analyze_sentiment_with_ai(text)
        fetched_comments.append({
            "content": text,
            "sentiment": sent,
            "confidence": conf,
            "date": (datetime.now() - timedelta(days=random.randint(0, 7))).strftime("%Y-%m-%d")
        })
    return df_sales, pd.DataFrame(fetched_comments)


def generate_mock_sales_data():
    dates = [datetime.now() - timedelta(days=i) for i in range(14)]
    dates.reverse()
    sales_data = []
    for date in dates:
        sales_data.append({"date": date.strftime("%Y-%m-%d"), "sales": random.randint(100, 300)})
    return pd.DataFrame(sales_data)


# ==========================================
# 3. Streamlit é¡µé¢
# ==========================================

with st.sidebar:
    st.title("æ§åˆ¶é¢æ¿")
    target_url = st.text_input("è¯·è¾“å…¥å•†å“é“¾æ¥:", value="https://detail.tmall.com/item.htm?id=XXXX")
    # æ·»åŠ ä¸€ä¸ªå¼€å…³ï¼Œå…è®¸ç”¨æˆ·é€‰æ‹©æ¨¡å¼
    use_real_crawler = st.checkbox("å¯ç”¨çœŸå®çˆ¬è™« (éœ€é…ç½®Cookie)", value=False)
    st.info("æç¤ºï¼šçœŸå®æŠ“å–é€Ÿåº¦è¾ƒæ…¢ï¼Œä¸”éœ€è¦æœ‰æ•ˆçš„Cookieã€‚")

st.title("ğŸ“Š åŸºäºAIçš„ç”µå•†å¹³å°å®¢æˆ·è´­ä¹°ä½“éªŒåˆ†æ")

if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary"):
    if use_real_crawler and HAS_CRAWLER:
        df_sales, df_comments = get_real_data(target_url)
    else:
        if use_real_crawler and not HAS_CRAWLER:
            st.warning("æœªæ‰¾åˆ° real_crawler.py æ–‡ä»¶ï¼Œå·²åˆ‡æ¢å›æ¨¡æ‹Ÿæ¨¡å¼ã€‚")
        df_sales, df_comments = fetch_mock_data(target_url)

    # --- ä¸‹é¢æ˜¯å±•ç¤ºé€»è¾‘ (ä¸ä¹‹å‰ç›¸åŒ) ---
    if not df_comments.empty:
        # æŒ‡æ ‡è®¡ç®—
        pos_rate = round((len(df_comments[df_comments['sentiment'] == 'æ­£é¢']) / len(df_comments)) * 100, 1)

        col1, col2, col3 = st.columns(3)
        col1.metric("åˆ†æè¯„è®ºæ•°", len(df_comments))
        col2.metric("AIå¥½è¯„ç‡", f"{pos_rate}%")
        col3.metric("æ•°æ®æ¥æº", "çœŸå®æŠ“å–" if use_real_crawler else "æ¨¡æ‹Ÿæ¼”ç¤º")

        st.markdown("---")
        c1, c2 = st.columns([2, 1])
        with c1:
            st.subheader("ğŸ“ˆ é”€é‡è¶‹åŠ¿ (æ¨¡æ‹Ÿè¡¥å…¨)")
            st.plotly_chart(px.line(df_sales, x='date', y='sales'), use_container_width=True)
        with c2:
            st.subheader("ğŸ’¬ æƒ…æ„Ÿåˆ†å¸ƒ")
            st.plotly_chart(px.pie(df_comments, names='sentiment', color='sentiment',
                                   color_discrete_map={'æ­£é¢': '#10b981', 'è´Ÿé¢': '#ef4444', 'ä¸­æ€§': '#9ca3af'}),
                            use_container_width=True)

        st.subheader("ğŸ“ è¯¦ç»†è¯„è®ºæ•°æ®")
        st.dataframe(df_comments, use_container_width=True)