import os
import time
import re
import streamlit as st
import pandas as pd
import concurrent.futures
from dotenv import load_dotenv

# å¼•å…¥åç«¯å‡½æ•°
from crawler import run_spider, get_search_links
# å¼•å…¥æ–°çš„æµå¼å‡½æ•°
from analysis import (
    analyze_single_product_stream,
    analyze_market_trends_stream,
    analyze_competitor_comparison_stream
)

load_dotenv()
default_key_from_env = os.getenv("ALIYUN_API_KEY")

st.set_page_config(page_title="ç”µå•†æ™ºèƒ½é€‰å“åˆ†æç³»ç»Ÿ", layout="wide")
st.markdown("<style>.stAppDeployButton {display:none;}</style>", unsafe_allow_html=True)

# === ä¾§è¾¹æ  ===
with st.sidebar:
    st.header("âš™ï¸ æ™ºèƒ½é…ç½®")
    user_api_key = st.text_input("é˜¿é‡Œäº‘ç™¾ç‚¼ API Key", value=default_key_from_env or "", type="password")
    st.markdown("---")
    st.header("ğŸ§  AI æ¨¡å‹é€‰æ‹©")
    selected_model = st.selectbox(
        "é€‰æ‹©åˆ†ææ¨¡å‹",
        ("deepseek-v3.2-exp", "deepseek-r1-0528", "qwen3-vl-32b-thinking", "qwen3-max"),
        index=0
    )
    st.markdown("---")
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰è®°å½•"):
        st.session_state.clear()
        st.rerun()

st.title("ğŸ›’ ç”µå•†è¯„è®ºæƒ…æ„Ÿåˆ†æä¸ç«å“æ¯”å¯¹ç³»ç»Ÿ")

# === åˆå§‹åŒ–çŠ¶æ€ ===
if 'last_query' not in st.session_state: st.session_state.last_query = ""
if 'df_result' not in st.session_state: st.session_state.df_result = None
if 'analysis_type' not in st.session_state: st.session_state.analysis_type = None
if 'product_info' not in st.session_state: st.session_state.product_info = ""
if 'comp_comments' not in st.session_state: st.session_state.comp_comments = []

# æŠ¥å‘ŠçŠ¶æ€
if 'report_single' not in st.session_state: st.session_state.report_single = None
if 'report_market' not in st.session_state: st.session_state.report_market = None
if 'report_comp' not in st.session_state: st.session_state.report_comp = None

# æ¨¡å‹è®°å½•çŠ¶æ€
if 'report_single_model' not in st.session_state: st.session_state.report_single_model = ""
if 'report_market_model' not in st.session_state: st.session_state.report_market_model = ""
if 'report_comp_model' not in st.session_state: st.session_state.report_comp_model = ""

# æ ‡å¿—ä½
if 'processing_comp' not in st.session_state: st.session_state.processing_comp = False

# === æ™ºèƒ½è¾“å…¥åŒº (ä¼˜åŒ–ç‰ˆï¼šå¢åŠ æŒ‰é’®ï¼Œè§£å†³å›è½¦æ— æ•ˆé—®é¢˜) ===
st.markdown("### ğŸ” æ™ºèƒ½æœç´¢")
col_input, col_btn = st.columns([5, 1], vertical_alignment="bottom")

with col_input:
    user_input = st.text_input(
        "è¾“å…¥æ¡†",
        placeholder="ğŸ‘‰ ç²˜è´´å¤©çŒ«/æ·˜å®é“¾æ¥ï¼ˆå•å“åˆ†æï¼‰ æˆ– è¾“å…¥å…³é”®è¯ï¼ˆè‡ªåŠ¨ç«å“è°ƒç ”ï¼‰...",
        label_visibility="collapsed"
    )

with col_btn:
    # æ˜¾å¼çš„æœç´¢æŒ‰é’®
    start_analysis = st.button("ğŸš€ ç«‹å³åˆ†æ", type="primary", use_container_width=True)


def is_url(text): return re.search(r'(http|https|tmall\.com|taobao\.com)', text)


# === è§¦å‘é€»è¾‘ (åŒæ—¶æ”¯æŒå›è½¦å’ŒæŒ‰é’®ç‚¹å‡») ===
# é€»è¾‘ï¼šå¦‚æœç‚¹å‡»äº†æŒ‰é’®ï¼Œæˆ–è€…è¾“å…¥å†…å®¹å‘ç”Ÿäº†å˜åŒ–ä¸”ä¸ä¸ºç©º
trigger_search = start_analysis or (user_input and user_input != st.session_state.last_query)

if trigger_search:
    st.session_state.last_query = user_input

    # === å¼ºåˆ¶é‡ç½®æ‰€æœ‰æ—§çŠ¶æ€ (è§£å†³â€œæ— æ³•è¾“å…¥â€çš„æ ¸å¿ƒ) ===
    st.session_state.df_result = None
    st.session_state.comp_comments = []  # æ¸…ç©ºä¹‹å‰çš„ç«å“
    st.session_state.report_single = None
    st.session_state.report_market = None
    st.session_state.report_comp = None
    st.session_state.report_comp_model = ""
    st.session_state.processing_comp = False  # é‡ç½®å¤„ç†æ ‡å¿—ä½

    if is_url(user_input):
        # === æ¨¡å¼ Aï¼šå•å“åˆ†æ ===
        st.session_state.analysis_type = 'single'
        st.toast("ğŸ”— è¯†åˆ«ä¸ºé“¾æ¥ï¼Œå¼€å§‹å•å“åˆ†æ...")
        with st.spinner('ğŸ•·ï¸ æ­£åœ¨çˆ¬å–å•†å“è¯„è®ºæ•°æ®...'):
            res, title = run_spider(user_input, worker_id=1)
        if "Error" in res:
            st.error(res)
        else:
            st.session_state.product_info = title
            st.session_state.df_result = pd.read_csv(res, encoding='utf-8-sig')
            st.success("æŠ“å–æˆåŠŸ")
    else:
        # === æ¨¡å¼ Bï¼šå…³é”®è¯è‡ªåŠ¨ç«å“/å¸‚åœºè°ƒç ” ===
        st.session_state.analysis_type = 'market'
        st.toast(f"ğŸ” è¯†åˆ«ä¸ºå…³é”®è¯ï¼Œè‡ªåŠ¨å¯åŠ¨å…¨ç½‘ç«å“è°ƒç ”...")
        with st.spinner('ğŸ•µï¸â€â™‚ï¸ æ­£åœ¨æœç´¢å¸‚åœºçƒ­é”€ç«å“...'):
            links = get_search_links(user_input, count=3)

        if links:
            all_cmts = []
            st.session_state.product_info = f"å…¨ç½‘è°ƒç ”ï¼š{user_input}"
            with st.spinner('ğŸš€ å¤šçº¿ç¨‹é‡‡é›†ç«å“æ•°æ®ä¸­...'):
                with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                    futures = [executor.submit(run_spider, link, i + 1) for i, link in enumerate(links)]
                    for f in concurrent.futures.as_completed(futures):
                        res, title = f.result()
                        if res and "Error" not in res:
                            try:
                                t_df = pd.read_csv(res, encoding='utf-8-sig')
                                if 'content' in t_df.columns: all_cmts.extend(t_df['content'].tolist())
                            except:
                                pass
            if all_cmts:
                st.session_state.df_result = pd.DataFrame({'content': all_cmts})
                st.success(f"è°ƒç ”å®Œæˆï¼Œå…±é‡‡é›† {len(all_cmts)} æ¡å¸‚åœºè¯„è®º")
        else:
            st.error("æœªæ‰¾åˆ°ç›¸å…³å•†å“ï¼Œè¯·å°è¯•æ›´æ¢å…³é”®è¯")

# === å±•ç¤ºä¸åˆ†æåŒº ===
if st.session_state.df_result is not None:
    df = st.session_state.df_result
    st.markdown("---")

    # æ ¹æ®æ¨¡å¼æ˜¾ç¤ºä¸åŒçš„æ ‡é¢˜
    is_single = (st.session_state.analysis_type == 'single')
    if is_single:
        st.subheader(f"ğŸ“¦ æœ¬å“æ•°æ®ï¼š{st.session_state.product_info}")
        expander_title = "ğŸ“ æŸ¥çœ‹æœ¬å“åŸå§‹è¯„è®º & ä¸‹è½½"
        download_name = "single_product_data.csv"
    else:
        st.subheader(f"ğŸ“Š å¸‚åœºè°ƒç ”æ•°æ®ï¼š{st.session_state.product_info}")
        expander_title = "ğŸ“ æŸ¥çœ‹é‡‡é›†åˆ°çš„ç«å“/å¸‚åœºè¯„è®º & ä¸‹è½½"
        download_name = "market_research_data.csv"

    with st.expander(expander_title, expanded=False):
        st.dataframe(df, use_container_width=True)
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å½“å‰åˆ†ææ•°æ® (.csv)",
            data=df.to_csv(index=False).encode('utf-8-sig'),
            file_name=f"{download_name}_{int(time.time())}.csv",
            mime='text/csv'
        )

    # ç¡®å®šå½“å‰é¡µé¢å¯¹åº”çš„ Key
    rpt_key = 'report_single' if is_single else 'report_market'
    mod_key = 'report_single_model' if is_single else 'report_market_model'

    saved_rpt = st.session_state[rpt_key]
    saved_mod = st.session_state[mod_key]

    # === AI åˆ†æåŒº ===
    st.markdown("### ğŸ§  æ·±åº¦åˆ†ææŠ¥å‘Š")

    ai_btn_disabled = False
    if not user_api_key:
        st.warning("âš ï¸ è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½®é˜¿é‡Œäº‘ API Key")
        ai_btn_disabled = True

    # å¦‚æœå·²æœ‰æŠ¥å‘Š
    if saved_rpt:
        st.info(f"å½“å‰å±•ç¤ºçš„æ˜¯ **{saved_mod}** ç”Ÿæˆçš„æŠ¥å‘Š")
        st.markdown(saved_rpt)
        st.markdown("---")

        btn_text = f"ğŸ”„ åˆ‡æ¢åˆ° {selected_model} å¹¶é‡æ–°ç”Ÿæˆ" if selected_model != saved_mod else "ğŸ”„ é‡æ–°ç”Ÿæˆ"

        if st.button(btn_text, disabled=ai_btn_disabled or st.session_state.processing_comp):
            st.session_state[rpt_key] = None
            st.session_state[mod_key] = ""
            st.rerun()

    # å¦‚æœæ²¡æœ‰æŠ¥å‘Š
    else:
        # æŒ‰é’®æ–‡æ¡ˆåŒºåˆ†
        gen_btn_text = "âœ¨ ç”Ÿæˆå•å“ä½“éªŒæŠ¥å‘Š" if is_single else "âœ¨ ç”Ÿæˆå¸‚åœºè¶‹åŠ¿/ç«å“è°ƒç ”æŠ¥å‘Š"

        if st.button(f"{gen_btn_text} ({selected_model})", type="primary", disabled=ai_btn_disabled):
            comments = df['content'].tolist()
            st.session_state[mod_key] = selected_model

            if is_single:
                stream_gen = analyze_single_product_stream(comments, user_api_key, model=selected_model)
            else:
                stream_gen = analyze_market_trends_stream(comments, user_api_key, model=selected_model)

            full_text = st.write_stream(stream_gen)
            st.session_state[rpt_key] = full_text
            st.rerun()

    # === ç«å“æ¯”å¯¹åŒº (ä»…åœ¨å•å“åˆ†ææ¨¡å¼ä¸‹å‡ºç°) ===
    # é€»è¾‘ï¼šå¦‚æœæ˜¯å…³é”®è¯æœç´¢ï¼ˆå¸‚åœºæ¨¡å¼ï¼‰ï¼Œæœ¬èº«å°±æ˜¯ç«å“åˆ†æï¼Œä¸éœ€è¦å†æ˜¾ç¤ºè¿™ä¸ªåŒºåŸŸ
    if is_single and st.session_state.report_single:
        st.markdown("---")
        st.markdown("### âš”ï¸ è¿›é˜¶åŠŸèƒ½ï¼šç«å“æ¯”å¯¹")
        st.caption("å·²å®Œæˆæœ¬å“åˆ†æï¼Œç°åœ¨å¯ä»¥é‡‡é›†ç«å“æ•°æ®è¿›è¡Œå·®å¼‚åŒ–æ¯”å¯¹ã€‚")

        has_comp_data = len(st.session_state.comp_comments) > 0

        # 1. é¡¶éƒ¨æ“ä½œæ 
        col_act1, col_act2 = st.columns([1, 4])
        with col_act1:
            if not has_comp_data:
                # æŠ“å–æŒ‰é’®
                if st.button("ğŸ” è‡ªåŠ¨æŠ“å– 3 ä¸ªç«å“", disabled=st.session_state.processing_comp or ai_btn_disabled):
                    st.session_state.processing_comp = True
                    st.rerun()
            else:
                # æ¸…ç©ºæŒ‰é’®
                if st.button("ğŸ”„ æ¸…ç©ºç«å“é‡æŠ“", disabled=st.session_state.processing_comp):
                    st.session_state.comp_comments = []
                    st.session_state.report_comp = None
                    st.session_state.report_comp_model = ""
                    st.rerun()

        with col_act2:
            if has_comp_data:
                st.success(f"âœ… å·²å°±ç»ªï¼š{len(st.session_state.comp_comments)} æ¡ç«å“æ•°æ®")
            elif st.session_state.processing_comp:
                st.info("ğŸƒâ€â™‚ï¸ æ­£åœ¨åŠªåŠ›æŠ“å–ä¸­ï¼Œè¯·ç¨å€™...")

        # 2. æŠ“å–é€»è¾‘
        if st.session_state.processing_comp and not has_comp_data:
            target_product = st.session_state.product_info
            if not target_product or target_product == "æœªçŸ¥å•†å“":
                st.warning("æœªèƒ½è·å–å•†å“æ ‡é¢˜ã€‚")
                st.session_state.processing_comp = False
                st.rerun()
            else:
                st.toast(f"æœç´¢ç«å“ï¼š{target_product[:15]}...")
                with st.status("æ­£åœ¨å¯»æ‰¾å¹¶é‡‡é›†æœ€å¼ºå¯¹æ‰‹æ•°æ®...", expanded=True) as status:
                    st.write("ğŸ” æ­£åœ¨æœç´¢ç«å“é“¾æ¥...")
                    comp_links = get_search_links(target_product, count=3)

                    if comp_links:
                        st.write(f"âœ… æ‰¾åˆ° {len(comp_links)} ä¸ªç«å“ï¼Œå¯åŠ¨å¤šçº¿ç¨‹é‡‡é›†...")
                        temp_comp_comments = []


                        def task_wrapper(args):
                            link, idx = args
                            return run_spider(link, worker_id=idx + 1)


                        progress_bar = st.progress(0)
                        task_args = [(link, i) for i, link in enumerate(comp_links)]

                        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
                            results = list(executor.map(task_wrapper, task_args))

                        for i, (res_file, _) in enumerate(results):
                            progress_bar.progress((i + 1) / len(comp_links))
                            if res_file and "Error" not in res_file:
                                try:
                                    c_df = pd.read_csv(res_file, encoding='utf-8-sig')
                                    temp_comp_comments.extend(c_df['content'].tolist())
                                except:
                                    pass

                        if len(temp_comp_comments) == 0:
                            status.update(label="âŒ é‡‡é›†å¤±è´¥", state="error")
                            st.error("æœªé‡‡é›†åˆ°æœ‰æ•ˆè¯„è®ºã€‚")
                        else:
                            st.session_state.comp_comments = temp_comp_comments
                            status.update(label="âœ… é‡‡é›†å®Œæˆï¼", state="complete")
                            time.sleep(1)
                    else:
                        status.update(label="âŒ æœªæ‰¾åˆ°ç«å“é“¾æ¥", state="error")
                        st.error("æœªæ‰¾åˆ°ç›¸å…³ç«å“é“¾æ¥ã€‚")

                st.session_state.processing_comp = False
                st.rerun()

        # 3. æ•°æ®å±•ç¤ºä¸ä¸‹è½½
        if has_comp_data:
            df_comp_display = pd.DataFrame({'content': st.session_state.comp_comments})
            df_comp_display['source'] = 'ç«å“'
            df_main_display = df.copy()
            df_main_display['source'] = 'æœ¬å“'
            df_all = pd.concat([df_main_display[['content', 'source']], df_comp_display[['content', 'source']]],
                               ignore_index=True)

            with st.expander("ğŸ“Š å±•å¼€æŸ¥çœ‹ç«å“è¯¦æƒ… & ä¸‹è½½åˆå¹¶æ•°æ®é›†", expanded=True):
                st.markdown(f"**æ•°æ®æ¦‚è§ˆï¼š** æœ¬å“ `{len(df)}` æ¡ vs ç«å“ `{len(df_comp_display)}` æ¡")
                st.dataframe(df_comp_display.head(50), use_container_width=True, height=200)

                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½å®Œæ•´å¯¹æ¯”æ•°æ®é›† (æœ¬å“+ç«å“ .csv)",
                    data=df_all.to_csv(index=False).encode('utf-8-sig'),
                    file_name=f"compare_data_full_{int(time.time())}.csv",
                    mime='text/csv',
                    key='dl_comp_all'
                )

            # 4. ç”ŸæˆæŠ¥å‘ŠæŒ‰é’®
            st.markdown("###")
            btn_label = f"âš–ï¸ å¼€å§‹ç”Ÿæˆç«å“å¯¹æ¯”æŠ¥å‘Š ({selected_model})"
            if st.session_state.report_comp:
                btn_label = "ğŸ”„ é‡æ–°ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"

            if st.button(btn_label, type="primary", disabled=ai_btn_disabled or st.session_state.processing_comp,
                         use_container_width=True):
                main_comments = df['content'].tolist()
                comp_comments = st.session_state.comp_comments
                st.session_state.report_comp_model = selected_model

                stream_gen = analyze_competitor_comparison_stream(
                    st.session_state.product_info,
                    main_comments,
                    comp_comments,
                    user_api_key,
                    model=selected_model
                )

                st.session_state.report_comp = st.write_stream(stream_gen)
                st.rerun()

        # 5. æŠ¥å‘Šå±•ç¤º
        if st.session_state.report_comp:
            st.markdown("---")
            st.subheader("âš–ï¸ ç«å“å·®å¼‚åŒ–å¯¹æ¯”æŠ¥å‘Š")
            st.info(f"ç”±æ¨¡å‹ **{st.session_state.report_comp_model}** ç”Ÿæˆ")
            st.markdown(st.session_state.report_comp)